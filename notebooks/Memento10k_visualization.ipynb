{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize examples of Memento10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from cv2 import imread, resize\n",
    "from scipy.stats import spearmanr\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, GlobalAveragePooling2D, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from timeit import default_timer as timer\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('../imgaug')\n",
    "from generator import VideoSeqGenerator, preprocess_i3d_rgb\n",
    "from vid_utils import load_video_opencv, plot_frames\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "\n",
    "import i3d_config as cfg\n",
    "from keras_models import build_i3d_custom, build_model_multigpu\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfosco-lambda\n"
     ]
    }
   ],
   "source": [
    "print(os.uname()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "\n",
    "data_path = '../../moments/10k_clean'\n",
    "labels_path = '../../moments/split'\n",
    "names_with_slash = True\n",
    "load_func = 'vids_opencv'\n",
    "\n",
    "# TRAIN_ON = 'rgb'\n",
    "\n",
    "if os.uname()[1] == 'visiongpu30':\n",
    "    data_path = '../../../moments_raw/sources_numpy_256/' if TRAIN_ON=='rgb' else '../../../moments_flow/sources_flow_down1_tvl1_skip1/'\n",
    "    labels_path = '../memento10k_labels/'\n",
    "    names_with_slash = False\n",
    "    load_func = 'npy_'+TRAIN_ON\n",
    "else:\n",
    "    data_path = '../../memento'\n",
    "    labels_path = '../../memento_data'\n",
    "    names_with_slash = True\n",
    "    load_func = 'vids_opencv'\n",
    "\n",
    "\n",
    "with open(os.path.join(labels_path, 'train_test_split_moments.pkl'), 'rb') as f:\n",
    "    tt_s = pickle.load(f)\n",
    "    \n",
    "train_names=[]\n",
    "val_names=[]\n",
    "test_names=[]\n",
    "\n",
    "# Fetch scores from ground truth json file with a defined T\n",
    "T = 180\n",
    "mem_scores_file = 'normalized_mem_scores_ma_T=%d.json' % T\n",
    "alpha_file = 'alphas_ma_T=%d.json' % T\n",
    "\n",
    "with open(os.path.join(labels_path, mem_scores_file)) as f:\n",
    "    name_to_mem = json.load(f)\n",
    "    \n",
    "with open(os.path.join(labels_path, alpha_file)) as f:\n",
    "    name_to_alpha = json.load(f)\n",
    "    \n",
    "# Getting dict in same format as vid names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name_to_mem_alpha={}\n",
    "\n",
    "if names_with_slash:\n",
    "    for n in tt_s[0]:\n",
    "        cl = n.split('_')[0]\n",
    "        cl = cl.replace('-','+')\n",
    "        newn = cl+'/'+'_'.join(n.split('_')[1:])\n",
    "        train_names.append(newn)\n",
    "\n",
    "    for n in tt_s[1]:\n",
    "        cl = n.split('_')[0]\n",
    "        cl = cl.replace('-','+')\n",
    "        newn = cl+'/'+'_'.join(n.split('_')[1:])\n",
    "        val_names.append(newn)\n",
    "        \n",
    "    for k,v in name_to_mem.items():\n",
    "        name_to_mem_alpha[k] = np.array([v, name_to_alpha[k]])\n",
    "    \n",
    "else:\n",
    "    train_names = sorted([ n[:-4]+'.npy' for n in tt_s[0] ])\n",
    "    val_names = sorted([ n[:-4]+'.npy' for n in tt_s[1] ])\n",
    "    for k,v in name_to_mem.items():\n",
    "        newk = k.replace('/','_').replace('+','-')[:-4]+'.npy' \n",
    "        name_to_mem_alpha[newk] = np.array([v, name_to_alpha[k]])\n",
    "    \n",
    "all_names_set = set(list(name_to_mem_alpha.keys()))\n",
    "test_names = list(all_names_set - set(train_names) - set(val_names))\n",
    "    \n",
    "\n",
    "\n",
    "print(train_names[:5])\n",
    "print(list(name_to_mem_alpha.keys())[:5])\n",
    "\n",
    "\n",
    "# Check if all names are in dict\n",
    "to_remove=[]\n",
    "for tn in train_names:\n",
    "    if not os.path.isfile(os.path.join(data_path, tn)):\n",
    "        to_remove.append(tn)\n",
    "    if tn not in name_to_mem_alpha.keys():\n",
    "        print('Train vid not in dict:',tn)\n",
    "        \n",
    "if to_remove:\n",
    "    for r in to_remove:\n",
    "        train_names.remove(to_remove)\n",
    "        \n",
    "to_remove=[]\n",
    "for tn in val_names:\n",
    "    if not os.path.isfile(os.path.join(data_path, tn)):\n",
    "        to_remove.append(tn)\n",
    "    if tn not in name_to_mem_alpha.keys():\n",
    "        print('Val vid not in dict:',tn)\n",
    "    \n",
    "if to_remove:\n",
    "    for r in to_remove:\n",
    "        val_names.remove(to_remove)\n",
    "\n",
    "to_remove=[]\n",
    "for tn in test_names:\n",
    "    if not os.path.isfile(os.path.join(data_path, tn)):\n",
    "        to_remove.append(tn)\n",
    "    if tn not in name_to_mem_alpha.keys():\n",
    "        print('Test vid not in dict:',tn)\n",
    "\n",
    "if to_remove:\n",
    "    for r in to_remove:\n",
    "        test_names.remove(r)\n",
    "\n",
    "print('Loaded %d train videos, %d val videos, %d test videos\\n' % (len(train_names), len(val_names), len(test_names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate generator\n",
    "\n",
    "gen_train_rgb = VideoSeqGenerator(files=train_names,\n",
    "                            batch_size=bs, \n",
    "                            has_label_col=False, \n",
    "                            dataset_path=data_path,\n",
    "                            label_csv= None, #'../../moments/split/moments_mini_categories.txt',\n",
    "                            augment=None,\n",
    "                            load_func=load_func,\n",
    "                            load_labels_func='mem_alpha',\n",
    "                            preprocess_func='fast_'+TRAIN_ON,\n",
    "                            remove_excess_files=False,\n",
    "                            shuffle=False,\n",
    "                            is_train=False,\n",
    "                            it_per_epoch=None,\n",
    "                            return_labels = True,\n",
    "                            verbose=True,\n",
    "                            str2label_dict = name_to_mem_alpha)\n",
    "\n",
    "gen_train_flow = VideoSeqGenerator(files=train_names,\n",
    "                            batch_size=bs, \n",
    "                            has_label_col=False, \n",
    "                            dataset_path=data_path,\n",
    "                            label_csv= None, #'../../moments/split/moments_mini_categories.txt',\n",
    "                            augment=None,\n",
    "                            load_func=load_func,\n",
    "                            load_labels_func='mem_alpha',\n",
    "                            preprocess_func='fast_'+TRAIN_ON,\n",
    "                            remove_excess_files=False,\n",
    "                            shuffle=False,\n",
    "                            is_train=False,\n",
    "                            it_per_epoch=None,\n",
    "                            return_labels = True,\n",
    "                            verbose=True,\n",
    "                            str2label_dict = name_to_mem_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generator\n",
    "\n",
    "k = 0\n",
    "\n",
    "batch, labels = gen_train_rgb.__getitem__(k)\n",
    "batch, labels = gen_train_flow.__getitem__(k)\n",
    "\n",
    "# Display\n",
    "for i,b in enumerate(batch):\n",
    "    mem, alpha = labels[i]\n",
    "    plot_frames(b, \n",
    "                title='%s | %d frames. STM: %s. Alpha: %s' % ('vid',len(b),mem,alpha),\n",
    "                is_optical_flow=True if TRAIN_ON=='flow' else False,\n",
    "                suptitle_y=0.89,\n",
    "                is_255image=True, \n",
    "                frames_to_show=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
